{"cells":[{"cell_type":"markdown","metadata":{"id":"2ea_mK-jkjiK"},"source":["#Mounting Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36513,"status":"ok","timestamp":1712682147795,"user":{"displayName":"GOSSIP GIRL","userId":"15382268686231289876"},"user_tz":-330},"id":"G5JlHEXFkiya","outputId":"d0755b74-d3c3-4e8f-bbbe-bb653b6deaa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"abOnYuHdloiP"},"source":["# Import Ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1712682165665,"user":{"displayName":"GOSSIP GIRL","userId":"15382268686231289876"},"user_tz":-330},"id":"dM7RsYqxF_by","outputId":"da3c2b6e-c068-4216-9c9b-7234e0e38f00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Apr  9 17:02:44 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   56C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KCk-jaRqSC5u"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.25-py3-none-any.whl (778 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m778.8/778.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib\u003e=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python\u003e=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow\u003e=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml\u003e=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch\u003e=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision\u003e=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm\u003e=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop\u003e=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas\u003e=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn\u003e=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (4.51.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.4.5)\n","Requirement already satisfied: numpy\u003e=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (24.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003e=1.1.4-\u003eultralytics) (2023.4)\n","Requirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003e=1.1.4-\u003eultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.14.0)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch\u003e=1.8.0-\u003eultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch\u003e=1.8.0-\u003eultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.3.0-\u003eultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.8.0-\u003eultralytics) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.8.0-\u003eultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.25\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"BCuF6qAflQg4"},"source":["# Convert DOTA to YOLO OBB"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5520,"status":"ok","timestamp":1712682281791,"user":{"displayName":"GOSSIP GIRL","userId":"15382268686231289876"},"user_tz":-330},"id":"dmRUz9-v6p8C","outputId":"833f4e5b-61bc-409d-fcba-ff00c9b9dc58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sxjp3hx-0pWG"},"outputs":[],"source":["import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6N2t2LPI4aKs"},"outputs":[],"source":["from pathlib import Path\n","from tqdm import tqdm\n","import cv2\n","\n","def my_convert_dota_to_yolo_obb(dota_root_path: str):\n","    \"\"\"\n","    Converts DOTA dataset annotations to YOLO OBB (Oriented Bounding Box) format.\n","\n","    The function processes images in the 'train' and 'val' folders of the DOTA dataset. For each image, it reads the\n","    associated label from the original labels directory and writes new labels in YOLO OBB format to a new directory.\n","\n","    Args:\n","        dota_root_path (str): The root directory path of the DOTA dataset.\n","\n","    Example:\n","        ```python\n","        from ultralytics.data.converter import convert_dota_to_yolo_obb\n","\n","        convert_dota_to_yolo_obb('path/to/DOTA')\n","        ```\n","\n","    Notes:\n","        The directory structure assumed for the DOTA dataset:\n","\n","            - DOTA\n","                ‚îú‚îÄ images\n","                ‚îÇ   ‚îú‚îÄ train\n","                ‚îÇ   ‚îî‚îÄ val\n","                ‚îî‚îÄ labels\n","                    ‚îú‚îÄ train_original\n","                    ‚îî‚îÄ val_original\n","\n","        After execution, the function will organize the labels into:\n","\n","            - DOTA\n","                ‚îî‚îÄ labels\n","                    ‚îú‚îÄ train\n","                    ‚îî‚îÄ val\n","    \"\"\"\n","    dota_root_path = Path(dota_root_path)\n","\n","    # Class names to indices mapping\n","    class_mapping = {\n","        \"pedestrian\": 0,\n","        \"people\": 1,\n","        \"bicycle\": 2,\n","        \"car\": 3,\n","        \"van\": 4,\n","        \"truck\": 5,\n","        \"tricycle\": 6,\n","        \"awning-tricycle\": 7,\n","        \"bus\": 8,\n","        \"motor\": 9,\n","    }\n","\n","    def convert_label(image_name, image_width, image_height, orig_label_dir, save_dir):\n","        \"\"\"Converts a single image's DOTA annotation to YOLO OBB format and saves it to a specified directory.\"\"\"\n","        orig_label_path = orig_label_dir / f\"{image_name}.txt\"\n","        save_path = save_dir / f\"{image_name}.txt\"\n","\n","        with orig_label_path.open(\"r\") as f, save_path.open(\"w\") as g:\n","            lines = f.readlines()\n","            for line in lines:\n","                parts = line.strip().split()\n","                if len(parts) \u003c 9:\n","                    continue\n","                class_name = parts[8]\n","                class_idx = class_mapping[class_name]\n","                coords = [float(p) for p in parts[:8]]\n","                normalized_coords = [\n","                    coords[i] / image_width if i % 2 == 0 else coords[i] / image_height for i in range(8)\n","                ]\n","                formatted_coords = [\"{:.6g}\".format(coord) for coord in normalized_coords]\n","                g.write(f\"{class_idx} {' '.join(formatted_coords)}\\n\")\n","\n","    for phase in [\"train\", \"val\"]:\n","        image_dir = dota_root_path / \"images\" / phase\n","        orig_label_dir = dota_root_path / \"labels\" / f\"{phase}_original\"\n","        save_dir = dota_root_path / \"labels\" / phase\n","\n","        save_dir.mkdir(parents=True, exist_ok=True)\n","\n","        image_paths = list(image_dir.iterdir())\n","        for image_path in tqdm(image_paths, desc=f\"Processing {phase} images\"):\n","            if image_path.suffix != \".jpg\":\n","                continue\n","            image_name_without_ext = image_path.stem\n","            img = cv2.imread(str(image_path))\n","            h, w = img.shape[:2]\n","            convert_label(image_name_without_ext, w, h, orig_label_dir, save_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":696043,"status":"ok","timestamp":1712684377675,"user":{"displayName":"GOSSIP GIRL","userId":"15382268686231289876"},"user_tz":-330},"id":"vbL7vbuslQBw","outputId":"be8232dd-4f26-43f8-ee19-03a3b5395e1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing train images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2352/2352 [28:03\u003c00:00,  1.40it/s]\n","Processing val images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [03:57\u003c00:00,  2.10it/s]\n"]}],"source":["#from ultralytics.data.converter import convert_dota_to_yolo_obb\n","\n","my_convert_dota_to_yolo_obb('/content/drive/MyDrive/yolodump/DOTA')"]},{"cell_type":"markdown","metadata":{"id":"7zDx6X4mSwYC"},"source":["# Install Yolo v8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":15,"status":"error","timestamp":1716988582073,"user":{"displayName":"GOSSIP GIRL","userId":"15382268686231289876"},"user_tz":-330},"id":"sQkVFBTGSwGB","outputId":"42386554-3e04-4c50-e012-8aed015ee0dc"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'ultralytics'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-7f8a827463a3\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from ultralytics import YOLO\n","import os\n","from IPython.display import display, Image\n","from IPython import display\n","display.clear_output()\n","!yolo mode=checks"]},{"cell_type":"markdown","metadata":{"id":"lcx8f5eFVsDX"},"source":["# Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":863386,"status":"ok","timestamp":1712685614484,"user":{"displayName":"GOSSIP GIRL","userId":"15382268686231289876"},"user_tz":-330},"id":"imPOg3lbR4Bz","outputId":"8d09404e-6360-4bda-c5df-7c32c4546eaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["YOLOv8x-obb summary: 390 layers, 69493056 parameters, 0 gradients, 264.0 GFLOPs\n","Ultralytics YOLOv8.1.45 üöÄ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=obb, mode=train, model=yolov8x-obb.pt, data=/content/drive/MyDrive/yolodump/yolo_data.yaml, epochs=1, time=None, patience=100, batch=2, imgsz=1024, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/obb/train3\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00\u003c00:00, 15.9MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=15 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1  10053601  ultralytics.nn.modules.head.OBB              [10, 1, [320, 640, 640]]      \n","YOLOv8x-obb summary: 390 layers, 69488241 parameters, 69488225 gradients, 263.9 GFLOPs\n","\n","Transferred 631/637 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/obb/train3', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00\u003c00:00, 72.3MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/yolodump/DOTA/labels/train... 2352 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2352/2352 [00:47\u003c00:00, 49.20it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/yolodump/DOTA/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yolodump/DOTA/labels/val... 500 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:06\u003c00:00, 73.68it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/yolodump/DOTA/labels/val.cache\n","Plotting labels to runs/obb/train3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 103 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n","Image sizes 1024 train, 1024 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/obb/train3\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["        1/1      6.64G     0.6804      1.047      1.308         46       1024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1176/1176 [09:54\u003c00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:22\u003c00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        500       9617       0.66      0.377      0.392      0.189\n","\n","1 epochs completed in 0.192 hours.\n","Optimizer stripped from runs/obb/train3/weights/last.pt, 139.5MB\n","Optimizer stripped from runs/obb/train3/weights/best.pt, 139.5MB\n","\n","Validating runs/obb/train3/weights/best.pt...\n","Ultralytics YOLOv8.1.45 üöÄ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLOv8x-obb summary (fused): 287 layers, 69458721 parameters, 0 gradients, 263.2 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:16\u003c00:00,  3.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        500       9617       0.66      0.377      0.392      0.189\n","            pedestrian        500        369          1          0      0.046     0.0159\n","                people        500         65          0          0          0          0\n","               bicycle        500        173          0          0          0          0\n","                   car        500        583      0.891      0.952      0.942      0.357\n","                   van        500         66          1          0     0.0359     0.0106\n","                 truck        500        216      0.811      0.972      0.974      0.695\n","              tricycle        500          7          1          0          0          0\n","       awning-tricycle        500       1375      0.997       0.94      0.993      0.422\n","                   bus        500          1          0          0          0          0\n","                 motor        500       6762      0.897      0.901      0.927      0.391\n","Speed: 0.6ms preprocess, 41.1ms inference, 0.0ms loss, 6.2ms postprocess per image\n","Results saved to \u001b[1mruns/obb/train3\u001b[0m\n"]}],"source":["from ultralytics import YOLO\n","\n","# Load a DOTA-pretrained YOLOv8n model\n","model = YOLO('yolov8x-obb.pt')\n","\n","# Display model information (optional)\n","model.info()\n","\n","# Train the model on the COCO8 example dataset for 100 epochs\n","results = model.train(data='/content/drive/MyDrive/yolodump/yolo_data.yaml', epochs=1, imgsz=1024, batch=2, device=0)\n","\n","# Run inference with the YOLOv8n model on the 'bus.jpg' image\n","# results = model('path/to/bus.jpg')"]},{"cell_type":"markdown","metadata":{"id":"Ie39wdbyyOC3"},"source":["Test model on image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkElTZ-WyL1G"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Load the trained YOLOv8 model\n","model = YOLO('path/to/your/trained/model.pt')\n","\n","# Specify the path to your test image\n","image_path = 'path/to/your/test/image.jpg'\n","\n","# Perform prediction on the test image\n","results = model.predict(source=image_path, save=True, save_txt=True, conf=0.25)\n","\n","# Print the predicted bounding boxes and class labels\n","for result in results:\n","    boxes = result.boxes\n","    for box in boxes:\n","        cls_name = result.names[box.cls.item()]\n","        conf = box.conf.item()\n","        print(f\"Class: {cls_name}, Confidence: {conf:.2f}, Bounding Box: {box.xyxy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6ID_nuMybNn"},"outputs":[],"source":["# model = YOLO('/path/to/your/local/folder/run_name/weights/best.pt')"]},{"cell_type":"markdown","metadata":{"id":"d96a8IFoyQ8Z"},"source":["Test model on video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJhtPk4aySr3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hMuWQnpycgH"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Load the trained YOLOv8 model\n","model = YOLO('path/to/your/trained/model.pt')\n","\n","# Specify the path to your input video\n","video_path = 'path/to/your/input/video.mp4'\n","\n","# Perform prediction on the video\n","results = model.predict(source=video_path, save=True, conf=0.25)\n","\n","# Print the predicted bounding boxes and class labels for each frame\n","for result in results:\n","    boxes = result.boxes\n","    for box in boxes:\n","        cls_name = result.names[box.cls.item()]\n","        conf = box.conf.item()\n","        print(f\"Class: {cls_name}, Confidence: {conf:.2f}, Bounding Box: {box.xyxy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYPitLFUg35r"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Load the trained YOLOv8 model\n","model = YOLO('best.pt')\n","\n","# Specify the path to your input video\n","video_path = '9.mp4'\n","\n","# Perform prediction on the video\n","results = model.predict(source=video_path, save=True, conf=0.25)\n","\n","# Iterate over the predicted results for each frame\n","for result in results:\n","    # Get the boxes, class names, and confidence scores\n","    boxes = result.boxes\n","    class_names = result.names\n","    confidences = boxes.conf\n","\n","    # Draw blue bounding boxes on the frame\n","    result_frame = result.plot(boxes=boxes, labels=class_names, conf=confidences, line_width=2, font_size=12, box_color=(255, 0, 0))\n","\n","# Save the processed video with blue bounding boxes\n","processed_video_path = 'predited9.mp4'\n","results.save(processed_video_path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOUB0Hpor5wjFGar86sZGcW","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}